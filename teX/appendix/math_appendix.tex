\chapter{Math Review}

\minititle{Preamble}

Add a short paragraph. Cite sources. Indicate how much the reader needs to skim. Think about the audience of this paper. Guide them to the resources as we are listing the definitions accordingly. Mention the importance and rank each definition (1,2,3 stars). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linear Algebra}
\subsection{Matrices}
\begin{definition}[Eigenvalue]
Suppose $P \in \F^{n \times n}$ is a square matrix. Then, the eigenvalues of the matrix $P$ are precisely the roots of the characteristic polynomial of $P$, given by $\text{char}_P(\lambda) = \det(P - \lambda I)$. The polynomial $\text{char}_P(\lambda)$ has degree $n$. So by the Fundamental Theorem of Algebra, $P$ has a multiset of $n$ eigenvalues.
\end{definition}

% \begin{definition}[Eigenvector]
% \end{definition}

\begin{definition}[Inverse Matrix]
Suppose there is a matrix $P \in \F^{m\times n}$. Then, $P^{-1}$ is its inverse matrix iff multiplying it by $P$ returns the identity matrix. That is, the inverse matrix must satisfy:
$$ P^{-1} P = I$$
\end{definition}

\begin{definition}[Transpose Matrix]
Suppose there is a matrix $P = (p_{ij}) \in \F^{m\times n}$. Then, its transpose matrix, $P^{T} = (q_{ij}) = (p_{ji}) \in \F^{n\times m}$ matrix whose columns are the rows of the original matrix.
\end{definition}

\begin{definition}[Conjugate Transpose Matrix]
Suppose there is a matrix $P = (p_{ij}) \in \C^{m\times n}$. Then, its conjugate transpose matrix, $P^{\dagger} = (q_{ij}) = (\overline{p_{ji}}) \in \F^{n\times m}$ is a matrix whose columns are the rows of the original matrix.
\end{definition}

\begin{definition}[Symmetric Matrix]
A matrix $P$ is symmetric iff it is equal to its transpose:
$$ P = P^{T}$$
\end{definition}

\begin{definition}[Hermitian Matrix]
A matrix $P$ is Hermitian iff it is equal to its conjugate transpose:
$$ P = P^{\dagger}$$
\end{definition}

\begin{definition}[Orthogonal Matrix]
A matrix $P$ is called orthogonal iff its transpose is its inverse:
$$ P^{T}=P^{-1}. $$
\end{definition}

\begin{theorem}[Orthogonal Group]
The set of {\em all} unitary matrices in $\F^{n\times n}$ is a matrix group. (It is called the {orthogonal group}.)
\end{theorem}

\begin{definition}[Unitary Matrix]
A matrix $P$ is called unitary iff its conjugate transpose is its inverse:
$$ P^{\dagger}=P^{-1}. $$
\end{definition}

\begin{theorem}[Unitary Group]
The set of {\em all} unitary matrices in $\C^{n\times n}$ is a matrix group. (It is called the {unitary group}.)
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\subsection{Proof: Real Symmetric Matrices have Real Eigenvectors}

\minititle{How does this relate to the rest of the thesis?}

Eigenvectors have a wide range of applications in various fields. As such, a result guranteeing the existence of real-valued eigenvalue is strong. For instance, the stationary distribution of a Markov chain is an eigenvector of its transition matrix. In other scenarios, right-eigenvectors represent the conditional expectation of a transition matrix, and so on! Additionally, this proof showcases techniques and tools used in this related domains of study. \newline

%\vspace{1em}

\blocktitle{Notation} For notational convenience, for any $N \in \N$, let $\N_{N} = \{1,\dots,N\}$.

\minititle{Proof}

In this section, we will prove that for any $M \times M$ real symmetric matrix, $S_M \in \R^{M \times M}$, there exists for some eigenvalue $\lambda$, a corrosponding \textbf{real} eigenvector $\vec{v} \in \R^M$. Prior to starting the main proof, we begin by proving a auxilliary lemma. \newline

\blocktitle{Lemma} Suppose we have a $M \times M$ real symmetric matrix with a some eigenvalue $\lambda$. If there we have a corrosponding eigenvector $v \in \Cc^M$, then every entry of $v$, say $v_i$ is equal to a \textbf{real} linear combination of the other entries $v_j \mid j \neq i$. So, we will show that:
$$\forall i \in \N_{M}: v_i =  {\sum_{j \neq i} c_j v_j} \quad (c_j \in \R)$$

\lemmaproof \newline

%\newpage 

\noindent Now, leveraging the result of this lemma, we will prove the main theorem.

\begin{theorem}[Taqi] Suppose we have a $M \times M$ real symmetric matrix, $S_M$. Then, we will show that there exists for some eigenvalue $\lambda$, a corrosponding \textbf{real} eigenvector $\vec{v} \in \R^M$.
\end{theorem}

\taqiproof

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Probability Theory}

Please refer to \cite{blitz} as a resource; the definitions were sourced from there. For the definitions and theorems covered in Section A.1, consider checking out Chapter 3: Random Variables and their distributions. For Order Statistics, consider Chapter 8, Section 6: Order Statistics.

\subsection{Random Variables}

\begin{definition}[Random Variable]
A random variable $X: \Omega \to \R$ is a function from some sample space $\Omega = \{s_i\}_{i=1}^n$ to the real numbers $\R$. The sample space is taken to be any set of events such that the probability function corrosponding to the random variable, $p_X$ exhausts over all the events in $\Omega$. In other words, we expect $\int_\Omega p_X(s) = 1$.
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\minititle{PDFs}

\begin{definition}[Probability Density Function]
For a continuous r.v. $X$ with CDF $F$, the probability density function (PDF) of $X$ is the derivative $f$ of the CDF, given by $f(x) = F'(x)$. The support of $X$, and of its distribution, is the set of all $x$ where $f(x) > 0$.
\end{definition}

\begin{theorem}[Characterizing the PDF]
A probability density function is characterized by a few properties that are necessary for it to be valid. They are as follows:
  \begin{enumerate}
    \item Non-negativity: the PDF must be a non-negative valued function everywhere.
      $$ f(x) \geq 0  $$
    \item Integrates to 1: the PDF must integrate to 1 when integrated over its entire support.
    $$ \int_{-\infty}^{\infty} f(x) dx = 1 $$
    \end{enumerate}
\end{theorem}

\begin{example}[Normal PDF]
For example, consider the probability density function for a r.v. $X \sim \Normal(\mu, \sigma)$.
$$\P(X = x) = \frac{1}{\sigma \sqrt{2 \pi}} \exp (-\frac{1}{2} \left(\frac{x - \mu}{\sigma}\right)^2 )$$
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\minititle{CDFs}

\begin{definition}[Cumulative Distribution Function]
The cumulative distribution function (CDF) of an r.v. $X$ is the function $F_X$ given by $F_X(x) = \P (X \leq x)$. When there is no risk of ambiguity, we sometimes drop the subscript and just write $F$ (or some other letter) for a CDF.
\end{definition}

\begin{theorem}[Characterizing the CDF]
A cumulative distribution function is characterized by a few properties that are necessary for it to be valid. They are as follows:
  \begin{enumerate}
    \item Monotonic function: the CDF must always be a monotonically increasing function. That is:
      $$ x_0 \leq x_1 \implies F(x_0) \leq F(x_1) $$
    \item Right-continuous: The CDF is continuous except possibly for having some jumps. Wherever there is a jump, the CDF is continuous from the right. That is, for any $a$, we have:
    $$ F(a) = \lim_{x \to a^+} F(x) $$
    \item Converges to 0 and 1 in its limits: since the CDF represents a cumulative probability, its limits must reflect that aspect of probability spaces. So, the CDF must satisfy:
    $$ \lim_{x \to -\infty} F(x) = 0 \and \lim_{x \to \infty} F(x) = 1 $$
  \end{enumerate}
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\minititle{Independence}

\begin{definition}[Independence]
Random variables X and Y are said to be independent if $\forall x,y \in \R$:
$$ \P(X \leq x, Y \leq y) = \P(X \leq x) \P(Y \leq y)$$
If the variables are discrete, then this is equivalent to the condition:
$$ \P(X = x, Y = y) = \P(X = x) \P(Y = y) $$
\end{definition}

\begin{definition}[i.i.d]
A vector of random variables $\vec{X} = (X_i)_{i = 1}^N$ is said to be i.i.d (independent and identially distributed) is each of its entries $X_i$ are exactly so. 
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Statistics}

\begin{definition}[Statistic]
A statistic is formally defined as a function of a vector of random variables. So, for instance $f$ is a statistic of a vector of random variables $\bar{X}$. Its observed value is given by $f(\vec{X})$.
\end{definition}

\begin{example}[Mean Statistic]
For instance, the mean of a random sample $\vec{X}$ is a statistic. Formally, we would define the statistic $f : \vec{X} \to \frac{\sum_i x_i}{N}$. So the mean of the random sample is defined as $\bar{x} = f(\vec{X})$.
\end{example}

\minititle{Order Statistics}

\begin{definition}[Order Statistic]
Suppose $\vec{X} = \{X_i\}_{i = 1}^N$ is an ordered vector of random variables. Then, the $i^{th}$ order statistic of $X$ is given by $X_i$.
\end{definition}

\begin{example}[Order Statistic]
Suppose $X = (20,7,2,1)$. The smallest (fourth) order statistic is $1$. The second order statistic is $7$. The largest (first) order statistic is $20$.
\end{example}

% \minititle{Theoretical Results}
% 
% Here, talk about the results in Chapter 8 of Blitzstein with the following pairs: (Uniform, Beta) and (Exponential, Gamma). Add the simulations. Beef up this sub-subsection.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Markov Chains}

\minititle{How does this relate to the rest of the thesis?}

Tie back the relevance of this section to the rest of this thesis. This will come up in Appendix D. It is also important because transition matrices are representations of markov chains. Please refer to \cite{blitz}, Chapter 11 for all this information.

\begin{definition}[Markov Chain] Say a set of random variables $X_i$ each take a value in a set, called the state space, $S_M = \{1,2,\dots,M\}$. Then, a sequence of such random variables $X_0,X_1,\dots,X_n$ is called a Markov Chain if the following conditions are satisifed:
\end{definition}

\begin{itemize}
\item $\forall X_i:$ $X_i$ has support and range $S_M = \{1,2,...,M\}$.
\item $\textbf{(Markov Property)}$ The transition probability from state $i \to j$, given by $\Prb(X_{n+1} = j \mid X_n = i)$ is conditionally independent from all past events in the sequence $X_{n-1} = i',X_{n-2} = i'', \dots,X_0 = i^{(n-1)}$, excluding the present/last event in the sequence. In other words, given the present, the past and the future are conditionally independent. So, $\forall i,j \in S_M$, we observe:
$$ \Prb(X_{n+1} = j \mid X_n = i) = \Prb(X_{n+1} = j \mid X_n = i, X_{n-1} = i', \dots,X_0 = i^{(n-1)})$$
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\minititle{Transition Matrices}

\begin{definition}[Transition Matrix]
Take a Markov Chain with states $\{\oneto[M]\}$. Letting $q_{ij} = \P(X_{n+1} = j \mid X_n = i)$ be the transition probability from $i \to j$, then the matrix $Q=(q_{ij})$ is the $\textit{transition matrix}$ of the chain. 
\end{definition}

\begin{itemize}
\item $Q$ is a non-negative matrix. So every entry $q_{ij} \in \R^+$ is non-negative. This follows because probabilities are necessarily non-negative values.
\item For this transition matrix to be valid, its rows have to be stochastic, meaning their entries sum to 1. This may be understood as applying the law of total probability to the event of transitioning from any given state $i \in S_M$. In other words, the chain has to go somewhere with probability 1.
$$\forall i \in \N_M: \sum_{j \in \N_M} q_{ij} = 1$$
\item Note, it is NOT necessary that the converse holds. The columns of our transition matrix need not sum to 1 for it to be a valid transition matrix.
\end{itemize}

\begin{definition}[n-Step Transition Probability] The $n-$step transition probability of $i \to j$ is the probability of being at $j$ exactly $n$ steps after being at $i$. We denote this value $q_{ij}^{(n)}:$
\end{definition}

$$ q_{ij}^{(n)}: \Prb(X_n = j \mid X_0 = i)$$
Realize:
$$q_{ij}^{(2)} = \sum_{k \in S_M} q_{ik}\cdot q_{kj}$$
Because by definition, a Markov Chain is closed under a support/range of $S_M$ so the event $i \to j$ may have taken any intermediate step $k \in S_M$. Realize by notational equivalence, $Q^2 = (q_{ij}^{(2)})$. Inducting over $n$, we then obtain that:

$$q_{ij}^{(n)} \text{ is the } (i,j) \text{ entry of } Q^n$$

\begin{definition}[Marginal Distribution of $X_n$] Let $\textbf{t} = (t_1,t_2,\dots,t_M)$ such that $\forall i \in S_M : t_i = \Prb(X_0 = i)$. So, $\textbf{t} \in \R^{1 \times M}$. Then, the marginal distribution of $X_n$ is given by the product of the vector $\textbf{t} Q^n \in \R^{1 \times M}$. That is, the $j^{th}$ component of that vector is $\P(X_n = j)$ for any $j \in S_M$. We may call $\textbf{t}$ an initial state distribution.
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\minititle{Classification of states}

\begin{itemize}
\item A state $i \in S_M$ is said to be $\textbf{recurrent}$ if starting from $i$, the probability is 1 that the chain will $\textit{eventually}$ return to $i$. If the chain is not recurrent, it is $\textbf{transient}$, meaning that if it starts at $i$, there is a non-zero probability that it never returns to $i$.

\item Caveat: As we let $n \to \infty$, our Markov chain will gurantee that all transient states will be left forever, no matter how small the probability is. This can be proven by letting the probability be some $\epsilon$, then realizing that by the support of $\text{Geom}(\epsilon)$ is always some finite value, then the equivalence between the Markov property and independent Geometric trials gurantees the existence of some finite value such that there is a success of never returning to $i$.
\end{itemize}

\begin{definition}[Reducibility] A Markov chain is said to be $\textbf{irreducible}$ if for any $i,j \in S_M$, it is possible to go from $i \to j$ in a finite number of steps with positive probability. In other words:
\end{definition}

$$\forall i,j \in S_M: \exists n \in \mathbb{N} : q_{ij}^{(n)} > 0$$
\begin{itemize}
\item From our quantifier formulation of irreducible Markov chains, note that we can equivalently say that a chain is irreducible if there is integer $n \in \mathbb{N}$ such that the $(i,j)$ entry of $Q^n$ is positive for any $i,j$.

\item A Markov chain is $\textbf{reducible}$ if it is not $\textbf{irreducible}$. Using our quantifier formulation, it means that it suffices to find transient states so that:

$$\exists i,j \in S_M: \nexists n \in \mathbb{N} : q_{ij}^{(n)} > 0$$
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
