\chapter{Random Matrices}

\section{Introduction}
As promised, here is what a random matrix is.

\begin{definition}[Random Matrix]
A (homogenous) random matrix is any matrix $M \in \F^{N \times N}$ is a matrix whose entries are i.i.d random variables. So, if a random matrix $M = (m_{ij})$ is $\mathcal{D}$-distributed, this is equivalent to saying $m_{ij} \sim \mathcal{D}$. In the scope of this thesis, we will only work with homogenous random matrices. From thereonafter, assume every random matrix to be homogenously distributed. 
\end{definition}

\begin{example}
Let $\mathcal{D} = \Normal(0,1)$. 
\end{example}

\section{The Crew}

\begin{definition}[Random Matrix Ensemble]
A $\D$-distributed random matrix ensemble $\Ens$ over $\F^{N \times N}$ of size $K$ is defined as a set of $\D$-distributed random matrices $\Ens = \{P_i \sim \mathcal{D} \mid P_i \in \F^{N \times N}\}_{i = 1}^K$. In simple words, it is simply a collection of iterations of some specified class of random matrix.
\end{definition}

\subsection{Hermitian $\beta$-Ensembles}

\begin{definition}[Hermitian-Gaussian $\beta$-ensemble]
The Hermite $\beta$-ensemble is the ensemble of random matrices whose eigenvalues have the joint probability density function:
\begin{align*}
f_\beta(\lambda) = c_H^\beta \prod_{i < j} |\lambda_i - \lambda_j|^\beta e^{-1/2\sum_i \lambda_i^2}
\end{align*}
where the normalization constant $c_H^\beta$ is given by:
\begin{align*}
c_H^\beta = (2\pi)^{-n/2} \prod_{j = 1}^n \frac{\Gamma(1 + \beta/2)}{\Gamma(1 + \beta j/2)}
\end{align*}
They represent a matrix whose entries have $\beta$ real number components.
\end{definition}

Reference the person's work here and refer to the algorithm appendix on how to simualate general beta matrices.

\subsection{Erdos-Renyi $p$-Ensembles}

\section{Analytical Results}




